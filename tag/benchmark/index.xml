<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Benchmark | Xiaoqiang&#39;s Homepage</title>
    <link>http://xiaoqiangzhou.cn/tag/benchmark/</link>
      <atom:link href="http://xiaoqiangzhou.cn/tag/benchmark/index.xml" rel="self" type="application/rss+xml" />
    <description>Benchmark</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 16 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://xiaoqiangzhou.cn/media/icon_hudd244c7a401d7898701885a05ebe1cd4_6259_512x512_fill_lanczos_center_3.png</url>
      <title>Benchmark</title>
      <link>http://xiaoqiangzhou.cn/tag/benchmark/</link>
    </image>
    
    <item>
      <title>How to Make a Benchmark Analysis</title>
      <link>http://xiaoqiangzhou.cn/post/benchmark/</link>
      <pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://xiaoqiangzhou.cn/post/benchmark/</guid>
      <description>&lt;h3 id=&#34;cvpr-2019-single-image-deraining-a-comprehensive-benchmark-analysis&#34;&gt;[CVPR 2019] Single Image Deraining: A Comprehensive Benchmark Analysis&lt;/h3&gt;
&lt;h6 id=&#34;motivation&#34;&gt;Motivation:&lt;/h6&gt;
&lt;p&gt;It is thus unclear how these algorithms would perform on rainy images acquired “in the wild” and how we could gauge the progress in the field.&lt;/p&gt;
&lt;h6 id=&#34;pipeline&#34;&gt;Pipeline:&lt;/h6&gt;
&lt;ol&gt;
&lt;li&gt;Formulate the rainy image synthesis process (from simple to complex)&lt;/li&gt;
&lt;li&gt;Summarize the contribution (thorough methods/testing sets)&lt;/li&gt;
&lt;li&gt;Method: Introduce the training sets&lt;/li&gt;
&lt;li&gt;Method: Introduce the testing sets&lt;/li&gt;
&lt;li&gt;Method: Introduce the additional task-driven (object detection in rainy images) testing sets.&lt;/li&gt;
&lt;li&gt;Experiments: Objective comparison (PSNR, SSIM, NIQE, SSEQ, and BLIINDSII)&lt;/li&gt;
&lt;li&gt;Experiments: Subjective comparison (11 human raters)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;tpami-2021-cross-domain-facial-expression-recognition-a-unified-evaluation-benchmark-and-adversarial-graph-learning&#34;&gt;[TPAMI 2021] Cross-Domain Facial Expression Recognition: A Unified Evaluation Benchmark and Adversarial Graph Learning&lt;/h3&gt;
&lt;h6 id=&#34;motivation-1&#34;&gt;Motivation:&lt;/h6&gt;
&lt;ol&gt;
&lt;li&gt;Comprehensive and fair comparisons are lacking due to inconsistent choices of the source/target datasets and feature extractors.&lt;/li&gt;
&lt;li&gt;This journal paper is an extension work on their conference paper, which is published on ACM MM 2020. Therefore, the authors propose a novel method for this task.&lt;/li&gt;
&lt;/ol&gt;
&lt;h6 id=&#34;pipeline-1&#34;&gt;Pipeline:&lt;/h6&gt;
&lt;ol&gt;
&lt;li&gt;Category existing works by the training sets and backbone network.&lt;/li&gt;
&lt;li&gt;Build a simple baseline with ResNet-50 and take experiments to verify the influence of domain gap caused by the selected training sets.&lt;/li&gt;
&lt;li&gt;Conduct experiments to compare the effectiveness of different backbones under a baseline design.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Re-implement some SOTA methods manually and take thorough experiments with different training sets / backbone.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Evaluation Protocols: Dataset choice/Feature extractor choice&lt;/li&gt;
&lt;li&gt;Introduce the proposed method.&lt;/li&gt;
&lt;li&gt;Ablation study on the proposed method.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;tpami-2020-toward-bridging-the-simulated-to-real-gap-benchmarking-super-resolution-on-real-data&#34;&gt;[TPAMI 2020] Toward Bridging the Simulated-to-Real Gap: Benchmarking Super-Resolution on Real Data&lt;/h3&gt;
&lt;h3 id=&#34;cvpr-2020-cross-domain-document-object-detection-benchmark-suite-and-method&#34;&gt;[CVPR 2020] Cross-Domain Document Object Detection: Benchmark Suite and Method&lt;/h3&gt;
&lt;h3 id=&#34;wacv-2021-adaptiope-a-modern-benchmark-for-unsupervised-domain-adaptation&#34;&gt;[WACV 2021] Adaptiope: A Modern Benchmark for Unsupervised Domain Adaptation&lt;/h3&gt;
&lt;h3 id=&#34;todo--the-first-work-that-defines-the-setting-of-domain-generalization-task&#34;&gt;[TODO ] The first work that defines the setting of domain generalization task&lt;/h3&gt;
&lt;h3 id=&#34;submitted-to-neurips-21-ood-bench-benchmarking-and-understanding-out-of-distribution-generalization-datasets-and-algorithms&#34;&gt;[submitted to NeurIPS 21] OoD-Bench Benchmarking and Understanding Out-of-Distribution Generalization Datasets and Algorithms&lt;/h3&gt;
&lt;h3 id=&#34;domain-generalization-in-vision-a-survey&#34;&gt;Domain Generalization in Vision: A Survey&lt;/h3&gt;
&lt;h3 id=&#34;number-of-paper-titles-including-benchmark&#34;&gt;Number of paper titles including &amp;ldquo;benchmark&amp;rdquo;:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;ICCV 2021:&lt;/em&gt; 18. &lt;a href=&#34;https://openaccess.thecvf.com/ICCV2021?day=all&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;CVPR 2021:&lt;/em&gt; 17. &lt;a href=&#34;https://openaccess.thecvf.com/CVPR2021?day=all&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;ECCV 2020:&lt;/em&gt; 7.  &lt;a href=&#34;https://www.ecva.net/papers.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;CVPR 2020:&lt;/em&gt; 6.  &lt;a href=&#34;https://openaccess.thecvf.com/CVPR2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;TPAMI&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;&lt;i&gt;TPAMI&lt;/i&gt;&lt;/summary&gt;
&lt;pre&gt;
1. Title: &lt;b&gt;Toward Bridging the Simulated-to-Real Gap: Benchmarking Super-Resolution on Real Data&lt;/b&gt;
   Authors: TPAMI 2020
&lt;/pre&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;i&gt;ICCV 2021&lt;/i&gt;&lt;/summary&gt;
&lt;pre&gt;
1. Title: Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models
   Authors: Jingjing Liu
2. Title: Env-QA: A Video Question Answering Benchmark for Comprehensive Understanding of Dynamic Environments
    Authors: Ziyi Bai, Xilin Chen
3. &lt;b&gt;Title: FloW: A Dataset and Benchmark for Floating Waste Detection in Inland Waters&lt;/b&gt;
   Authors:  &lt;b&gt;Yoshua Bengio&lt;/b&gt;
4. Title: Webly Supervised Fine-Grained Recognition: Benchmark Datasets and an Approach
   Authors: Jian Zhang, Heng Tao Shen
5. Title: H2O: A Benchmark for Visual Human-Human Object Handover Analysis
   Authors: Yanfeng Wang, Cewu Lu
6. Title: RobustNav: Towards Benchmarking Robustness in Embodied Navigation
   Authors:
7. Title: Towards Real-World Prohibited Item Detection: A Large-Scale X-Ray Benchmark
   Authors:
8. &lt;b&gt;Title: Transparent Object Tracking Benchmark&lt;/b&gt;
   Authors: Haibin Ling
9. Title: E-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks
   Authors:
10. &lt;b&gt;Title: Benchmarking Ultra-High-Definition Image Super-Resolution&lt;/b&gt;
   Authors: Hongdong Li, Ming-Hsuan Yang
11. Title: Unidentified Video Objects: A Benchmark for Dense, Open-World Segmentation
   Authors:
12. &lt;b&gt;Title: Real-World Video Super-Resolution: A Benchmark Dataset and a Decomposition Based Learning Scheme&lt;/b&gt;
   Authors: Lei Zhang
13. &lt;b&gt;Title: HDR Video Reconstruction: A Coarse-To-Fine Network and a Real-World Benchmark Dataset&lt;/b&gt;
   Authors: Lei Zhang
&lt;/pre&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;i&gt;CVPR 2021&lt;/i&gt;&lt;/summary&gt;
&lt;pre&gt;
1. Title: &lt;b&gt;Multi-Shot Temporal Event Localization: A Benchmark&lt;/b&gt;
   Authors: Xiang Bai, Philip H. S. Torr
2. Title: &lt;b&gt;Towards Fast and Accurate Real-World Depth Super-Resolution: Benchmark Dataset and Baseline&lt;/b&gt;
   Authors:
3. Title: GMOT-40: A Benchmark for Generic Multiple Object Tracking
   Authors: Liang Lin
4. Title: ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis
   Authors: Ziwei Liu
&lt;/pre&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;i&gt;ECCV 2020&lt;/i&gt;&lt;/summary&gt;
&lt;pre&gt;
1. Title: &lt;b&gt;Real-World Blur Dataset for Learning and Benchmarking Deblurring Algorithms&lt;/b&gt;
   Authors: Jucheol Won, Sunghyun Cho
2. Title: &lt;b&gt;Towards causal benchmarking of bias in face analysis algorithms&lt;/b&gt;
   Authors: MIT, Amazon
&lt;/pre&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;i&gt;CVPR 2020&lt;/i&gt;&lt;/summary&gt;
&lt;pre&gt;
1. Title: &lt;b&gt;Cross-Domain Document Object Detection: Benchmark Suite and Method&lt;/b&gt;
   Authors: Yun Fu
2. Title: &lt;b&gt;Supervised Raw Video Denoising With a Benchmark Dataset on Dynamic Scenes&lt;/b&gt;
   Authors: Ronghe Chu, Jingyu Yang
&lt;/pre&gt;
&lt;/details&gt;
</description>
    </item>
    
  </channel>
</rss>
