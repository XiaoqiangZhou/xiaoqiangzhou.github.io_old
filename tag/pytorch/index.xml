<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PyTorch | Xiaoqiang&#39;s Homepage</title>
    <link>http://xiaoqiangzhou.cn/tag/pytorch/</link>
      <atom:link href="http://xiaoqiangzhou.cn/tag/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <description>PyTorch</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://xiaoqiangzhou.cn/media/icon_hudd244c7a401d7898701885a05ebe1cd4_6259_512x512_fill_lanczos_center_3.png</url>
      <title>PyTorch</title>
      <link>http://xiaoqiangzhou.cn/tag/pytorch/</link>
    </image>
    
    <item>
      <title>Code Notes</title>
      <link>http://xiaoqiangzhou.cn/post/code_notes/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://xiaoqiangzhou.cn/post/code_notes/</guid>
      <description>&lt;h4 id=&#34;提升效率的命令技巧&#34;&gt;提升效率的命令/技巧&lt;/h4&gt;
&lt;p&gt;alias命令
在~/.bashrc文件中添加如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;alias data=&amp;quot;cd /data1/username/exp_data&amp;quot;
alias codes=&amp;quot;cd /data1/username/codes&amp;quot;
alias ac_torch=&amp;quot;conda activate pytorch1.5.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后便可通过data和codes命令直接进入对应路径下&lt;/p&gt;
&lt;p&gt;关于~/.bashrc文件，可以理解为每次登陆时自动执行一次其中的内容&lt;/p&gt;
&lt;p&gt;直接在命令行执行export， alias等命令，有效期为本次登录期间。&lt;/p&gt;
&lt;p&gt;可以将自定义命令写入另一个文件~/.my_cmd，然后在~/.bashrc最后加入&lt;/p&gt;
&lt;p&gt;&lt;code&gt;source ~/.my_cmd&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;alias命令不光可以在~/.bashrc即linux平台使用，在git, cmder等软件中均可以进行配置。&lt;/p&gt;
&lt;p&gt;常用的命令比如ssh &lt;strong&gt;@&lt;/strong&gt;， tensorboard都可以通过alias命令简化&lt;/p&gt;
&lt;h4 id=&#34;git&#34;&gt;Git&lt;/h4&gt;
&lt;p&gt;git可以很方便的实现多机、多平台之间的代码同步。
这里假设本地使用一台机器编辑代码，在两个平台（github和公司的git仓库），多个机器上（组里的N台机器，公司的N台机器）进行代码同步。
做法：参见另一篇文章：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/226278333&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;周晓强：Git Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;h4 id=&#34;pip&#34;&gt;Pip&lt;/h4&gt;
&lt;p&gt;使用清华源下载：
&lt;code&gt;pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;vs-code&#34;&gt;VS Code&lt;/h4&gt;
&lt;p&gt;远程连接服务器：参考
&lt;a href=&#34;https://blog.csdn.net/weixin_42096901/article/details/105062195&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;windows下使用vscode远程连接Linux服务器进行开发&lt;/a&gt;
​&lt;/p&gt;
&lt;h4 id=&#34;pytorch安装&#34;&gt;PyTorch安装&lt;/h4&gt;
&lt;p&gt;首先使用nvidia-smi命令查看CUDA驱动版本，比如10.2&lt;/p&gt;
&lt;p&gt;在PyTorch网页（链接）寻找对应的命令，建议使用conda命令安装，同时cudatoolkit版本与上述CUDA驱动版本保持一致&lt;/p&gt;
&lt;p&gt;例如使用nvidia-smi命令后，显示版本为10.2, 则安装pytorch的命令为&lt;/p&gt;
&lt;p&gt;&lt;code&gt;conda install pytorch==1.5.0 torchvision==0.6.0 cudatoolkit=10.2 -c pytorch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意要安装cudatoolkit包，不然可能导致&lt;code&gt;torch.cuda.is_available()=False&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;注意：PyTorch的安装不涉及到cuda和cudnn的配置，可以认为在cudatoolkit中实现了类似功能&lt;/p&gt;
&lt;h4 id=&#34;tensorflow安装&#34;&gt;Tensorflow安装&lt;/h4&gt;
&lt;p&gt;Tensorflow的安装的大体思路：配置cuda和cudnn, 然后利用export添加到路径，之后再安装tensorflow。&lt;/p&gt;
&lt;p&gt;目前不太确定的是，你想要安装的cuda版本以及nvidia-smi显示的cuda版本以及系统/usr/local下的cuda版本之间的关系，以及是否会冲突等。&lt;/p&gt;
&lt;p&gt;首先检查本机是否已经配置好cuda和cudnn：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;检查cuda安装情况：执行nvcc -V命令，如果显示命令不存在，进行第2步；如果显示版本信息，进行第3步。&lt;/li&gt;
&lt;li&gt;cuda安装的确认：进入/usr/local/cuda/bin目录下，执行&lt;code&gt;nvcc -V&lt;/code&gt;。如果显示了版本信息，说明cuda安装了，但是没有加入系统路径，之后如果在第3步确认cudnn也确实安装好了，可以将cuda加入系统路径，进入第3步。如果/usr/local/cuda*路径不存在，说明没有安装cuda。cuda都没有配置的话，cudnn基本也没有配置，非正常退出。&lt;/li&gt;
&lt;li&gt;检查cudnn安装情况：在cuda目录下，执行&lt;code&gt;cat /path/to/cuda/include/cudnn.h | grep CUDNNMAJOR -A5&lt;/code&gt;如果显示出CUDNN_MAJOR，CUDNN_MA等信息，则证明安装成功。说明本机已经配置好cuda和cudnn，正常退出。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;cuda和cudnn环境准备好之后，即可安装tensorflow&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip install tensorflow-gpu==***&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;可以通过&lt;/p&gt;
&lt;p&gt;&lt;code&gt;import tensorflow as tf;tf.test.is_gpu_available()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;检查，正确的输出结果为： 















&lt;figure  id=&#34;figure-可以从log中看到gpu信息&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/posts/code_notes/1_hue7104633ab21bc6a823ef89ce84a2436_199856_0d54e6d0b08994821aad9326e5905609.png 400w,
               /media/posts/code_notes/1_hue7104633ab21bc6a823ef89ce84a2436_199856_2c8653a74068e04de82f90c07d7910e5.png 760w,
               /media/posts/code_notes/1_hue7104633ab21bc6a823ef89ce84a2436_199856_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;http://xiaoqiangzhou.cn/media/posts/code_notes/1_hue7104633ab21bc6a823ef89ce84a2436_199856_0d54e6d0b08994821aad9326e5905609.png&#34;
               width=&#34;720&#34;
               height=&#34;231&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      可以从log中看到GPU信息
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;可以从log中看到GPU信息&lt;/p&gt;
&lt;h4 id=&#34;cuda和cudnn的安装&#34;&gt;cuda和cudnn的安装：&lt;/h4&gt;
&lt;p&gt;首先安装cuda。cuda仓库网址：&lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit-archive&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CUDA Toolkit Archive&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;给文件运行权限 chmod + x &lt;strong&gt;.run, 然后运行./&lt;/strong&gt;.run，依次选择accept&amp;mdash;no&amp;mdash;yes，然后将cuda安装到你的目录下（建议指定自己的目录）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下载cudnn。cudnn仓库网址：&lt;a href=&#34;https://developer.nvidia.com/rdp/cudnn-archive&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cuDNN Archive&lt;/a&gt;
​
需要注册NVIDIA账号，根据名称，找对应刚才cuda版本的cudnn安装包下载解压。&lt;code&gt;tar -xzvf cudnn-**-linux-x64-v**.tgz&lt;/code&gt;，win10下下载cudnn时后缀可能被修改，重命名为**.tgz即可。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进行部分文件的拷贝，从cudnn解压后的cuda文件夹，复制到之前的cuda文件夹中：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;cp cuda/include/cudnn.h /path/to/your_cuda/include/
cp cuda/lib64/libcudnn* /path/to/your_cuda/lib64
chmod a+r /path/to/your_cuda/include/cudnn.h /path/to/your_cuda/lib64/libcudnn*
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;查看cuda和cudnn安装状态：分别为nvcc -V和&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;cat /path/to/your_cuda/include/cudnn.h | grep CUDNN_MAJOR -A5&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果输出正常版本号，则证明cuda和cudnn安装成功。
















&lt;figure  id=&#34;figure-nvcc--v查看安装的cuda版本&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/posts/code_notes/2_hu10a71d56ebc020aed6deac0607066265_2849_674099db9e7f2daf6a4dd4b7df21d8c8.png 400w,
               /media/posts/code_notes/2_hu10a71d56ebc020aed6deac0607066265_2849_0951221c47d782fce6f2007e04edd9d1.png 760w,
               /media/posts/code_notes/2_hu10a71d56ebc020aed6deac0607066265_2849_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;http://xiaoqiangzhou.cn/media/posts/code_notes/2_hu10a71d56ebc020aed6deac0607066265_2849_674099db9e7f2daf6a4dd4b7df21d8c8.png&#34;
               width=&#34;376&#34;
               height=&#34;65&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      nvcc -V查看安装的cuda版本
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-查看cudnn版本&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/posts/code_notes/3_hu3df6c53d633e6ef5f11526114bfd95cc_3703_991e7aa0a141841806320be208277f76.png 400w,
               /media/posts/code_notes/3_hu3df6c53d633e6ef5f11526114bfd95cc_3703_a9051bef438c078a2b86e4e9644ff529.png 760w,
               /media/posts/code_notes/3_hu3df6c53d633e6ef5f11526114bfd95cc_3703_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;http://xiaoqiangzhou.cn/media/posts/code_notes/3_hu3df6c53d633e6ef5f11526114bfd95cc_3703_991e7aa0a141841806320be208277f76.png&#34;
               width=&#34;465&#34;
               height=&#34;145&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      查看cudnn版本
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;如果cuda安装成功后，即nvcc -V显示正确版本号，但是cudnn却失败了，可以尝试选用稍旧版本的cudnn而非最新版&lt;/p&gt;
&lt;p&gt;tensorflow截止到1.15版本，都不支持cuda-10.2，为了安装tensorflow，需要手动配置cuda-10.0，并修改~/.bashrc文件中的&lt;code&gt;PATH&lt;/code&gt;和&lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;变量。&lt;/p&gt;
&lt;h4 id=&#34;pyrender安装&#34;&gt;PyRender安装&lt;/h4&gt;
&lt;p&gt;windows安装：缺少freetype依赖，发现是因为没有安装visual studio&lt;/p&gt;
&lt;h4 id=&#34;pytorch3d安装&#34;&gt;PyTorch3D安装&lt;/h4&gt;
&lt;p&gt;PyTorch3D是Facebook开源的3D视觉工具包，安装指引：&lt;a href=&#34;https://github.com/facebookresearch/pytorch3d/blob/master/INSTALL.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;链接&lt;/a&gt;
windows（无cpu）安装：使用以下命令（需要提前安装好torch, torchvision等工具包）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/facebookresearch/pytorch3d.git
cd pytorch3d
pip install -e .
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;linux常用命令&#34;&gt;Linux常用命令&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;tmux&lt;/strong&gt;：将程序放在后台执行，即使推出ssh登录，只要服务器没有关机，程序就不会终端。&lt;/p&gt;
&lt;p&gt;创建新的窗口 &lt;code&gt;tmux new -s your_name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;暂时退出当前窗口 &lt;code&gt;ctrl+b+d&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;结束终止当前窗口 &lt;code&gt;exit&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;查看已创建的窗口 &lt;code&gt;tmux ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;进入之前创建的窗口 &lt;code&gt;tmux attach -t your_name或tmux a -t your_name&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nohup&lt;/strong&gt;：也是将程序放在后台执行，在没有tmux的情况下，使用nohup是一个退而求其次的选择&lt;/p&gt;
&lt;p&gt;执行任务并放到后台 &lt;code&gt;nohup bash yourscript.sh &amp;gt; your_log.log 2&amp;gt;&amp;amp;1 &amp;amp;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;之后只能通过查看log文件，来了解程序运行输出情况。不能像tmux那样进入窗口查看。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;top，htop，ps -aux&lt;/strong&gt;：这三个都是用来查看本机运行的任务的，按需取用。&lt;code&gt;htop&lt;/code&gt;和&lt;code&gt;ps -aux&lt;/code&gt;可以比较方便的定位到具体的任务对应的PID进行，方便进行Kill&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;scp&lt;/strong&gt;：用来进行数据传输。&lt;/p&gt;
&lt;p&gt;服务器下载文件到本地：&lt;code&gt;scp username@server_ip_address:文件在服务器的路径  文件在本地的保存路径&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;本机文件传递给服务器： &lt;code&gt;scp 文件在本地的保存路径  username@server_ip_address:文件在服务器的路径&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;连接服务器需要指定端口时，加入-P （大写）参数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nvidia-smi，gpustat&lt;/strong&gt;：这两个命令都可以用来查看当前机器的显卡占用情况，gpustat需要使用pip进行安装，界面简洁好看些。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;tensorboard&lt;/strong&gt;：用于查看训练过程中的结果&lt;/p&gt;
&lt;p&gt;基本设置为：&lt;code&gt;tensorboard --logdir path_to_log --port your_port&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;之后用浏览器打开 http://localhost:your_port即可，默认端口6006&lt;/p&gt;
&lt;p&gt;打开服务器上的log文件&lt;/p&gt;
&lt;p&gt;连接服务器：&lt;code&gt;ssh -L 本地端口:127.0.0.1:服务器端口 username@server_ip_address&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在服务器上执行：&lt;code&gt;tensorboard --logdir path_to_log --port 服务器端口&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在本地浏览器打开：http://localhost:本地端口&lt;/p&gt;
&lt;p&gt;tensorboard的使用，需要pip安装tensorboard库，如果安装完之后还是没有，需要寻找对应的文件&lt;/p&gt;
&lt;p&gt;&lt;code&gt;alias tensorboard=&#39;python /home/username/anaconda3/envs/your_env_name/lib/python3.6/site-packages/tensorboard/main.py&#39;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which&lt;/p&gt;
&lt;p&gt;可以用于查看当前使用的命令路径，例如：&lt;code&gt;which nvcc&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;pytorch笔记&#34;&gt;PyTorch笔记&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;关于device&lt;/li&gt;
&lt;/ol&gt;
&lt;ol&gt;
&lt;li&gt;DataParallel会自动将输入数据映射到对应的模型device上，验证代码：&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def verify_device():
    class net(nn.Module):
        def __init__(self):
            super(net, self).__init__()
        
        def forward(self, inputs):
            print(&amp;quot;data&#39;s device in model: &amp;quot;, inputs.device)

    my_net = net()
    my_net = nn.DataParallel(my_net.cuda())  # my_net = my_net.cuda()
    inputs = torch.ones((16, 3, 256, 256))
    print(&amp;quot;data&#39;s device out model: &amp;quot;, inputs.device)
    my_net(inputs)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;利用DataParallel 只将模型放在GPU上，而没有将输入放在GPU上，输出结果如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data&#39;s device out model:  cpu
data&#39;s device in model:  cuda:0
data&#39;s device in model:  cuda:1
data&#39;s device in model:  cuda:2
data&#39;s device in model:  cuda:3
data&#39;s device in model:  cuda:5
data&#39;s device in model:  cuda:6
data&#39;s device in model:  cuda:7
data&#39;s device in model:  cuda:4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果使用注释中的&lt;code&gt;my_net = my_net.cuda()&lt;/code&gt;，则得到&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data&#39;s device out model:  cpu
data&#39;s device in model:  cpu
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;bug记录&#34;&gt;BUG记录&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;PyTorch的dataloader一旦执行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;for iter, batch in enumerate(dataloader):&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;会卡住很久，进入&lt;code&gt;__getitem__&lt;/code&gt;进行debug发现一直在读取图片，虽然我使用的并不是opencv库进行数据读取&lt;/p&gt;
&lt;p&gt;解决办法：在主程序中加入&lt;code&gt;cv2.setNumThreads(0)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;谷歌搜索关键字：pytorch dataloader stucks&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Tensorflow多次load模型(为了进行多次测试)时，可能会出现&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;ValueError: Variable *** already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? &lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这种情况，通常是需要在代码中加入，每次load模型前清理一次计算图&lt;code&gt;tf.reset_default_graph()&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;基于PyTorch的代码，训练效果还不错，测试效果很糟糕，排除过拟合的原因以及测试代码的问题。最后发现是该代码在测试时需要指定&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;model.train()&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;程序报错：&lt;code&gt;cudnn_status_not_initialized&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可能是因为当前显卡正在被其他任务占用&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;安装neural_renderer_pytorch&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;RuntimeError: Error compiling objects for extension&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解决办法：将pytorch的版本从1.5降到1.2&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;多卡GPU训练，保存的也是多卡模型，却需要单卡测试&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;Unexpected key(s) in state_dict: &amp;quot;module.*&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解决办法：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;model.load_state_dict({k.replace(&#39;module.&#39;, &#39;&#39;): v for k, v in torch.load(model_state_path).items()})&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;模型在GPU上训练，需要在CPU上测试，跑inference&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;解决办法：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ckpt = torch.load(model_path, map_location=torch.device(&amp;quot;cpu&amp;quot;))&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;程序报错: &lt;code&gt;ModuleNotFoundError: No module named ‘network’&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;原因：保存模型时使用的是&lt;code&gt;torch.save(model)&lt;/code&gt; 而不是&lt;code&gt;torch.save(model.state_dict)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解决办法：在执行模型保存命令的py文件路径下，再次读取模型，并使用&lt;code&gt;torch.save(model.state_dict)&lt;/code&gt;来保存模型&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
