<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Junjie Li | Xiaoqiang&#39;s Homepage</title>
    <link>http://xiaoqiangzhou.cn/author/junjie-li/</link>
      <atom:link href="http://xiaoqiangzhou.cn/author/junjie-li/index.xml" rel="self" type="application/rss+xml" />
    <description>Junjie Li</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jul 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://xiaoqiangzhou.cn/media/icon_hudd244c7a401d7898701885a05ebe1cd4_6259_512x512_fill_lanczos_center_3.png</url>
      <title>Junjie Li</title>
      <link>http://xiaoqiangzhou.cn/author/junjie-li/</link>
    </image>
    
    <item>
      <title>Image Inpainting with Contrastive Relation Network</title>
      <link>http://xiaoqiangzhou.cn/publication/icpr-2020-first/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://xiaoqiangzhou.cn/publication/icpr-2020-first/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;h3 id=&#34;method&#34;&gt;Method:&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-1-contrastive-relation-network&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/images/ICPR-first/ICPR_first_RN_hu9e499dfac01c6349ba2c25475203057f_80550_dfabc84121a6d145a7446db65427a00e.png 400w,
               /media/images/ICPR-first/ICPR_first_RN_hu9e499dfac01c6349ba2c25475203057f_80550_78d945d2888f75e75307b7082d1085dc.png 760w,
               /media/images/ICPR-first/ICPR_first_RN_hu9e499dfac01c6349ba2c25475203057f_80550_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;http://xiaoqiangzhou.cn/media/images/ICPR-first/ICPR_first_RN_hu9e499dfac01c6349ba2c25475203057f_80550_dfabc84121a6d145a7446db65427a00e.png&#34;
               width=&#34;760&#34;
               height=&#34;324&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 1: Contrastive Relation Network
    &lt;/figcaption&gt;&lt;/figure&gt;

Firstly, features from each semantic sub-region are aggregated to a node representation and the nodes representation matrix is refined by a graph convolutional network. Then, the refined node representation is distributed to a feature map and used to modulate the corresponding features in the decoder network. The constrastive learning is adopted to faciliate the node representation learning.&lt;/p&gt;
&lt;h3 id=&#34;experiments&#34;&gt;Experiments:&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-figure-2-some-qualitative-results-compared-with-state-of-the-arts-on-three-datasets&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /media/images/ICPR-first/new_comparison_hu515bf716bc1e00894b5ecf56365aca5d_4422147_227ec18cbae17f4c1e8f7312c7249f01.png 400w,
               /media/images/ICPR-first/new_comparison_hu515bf716bc1e00894b5ecf56365aca5d_4422147_bd4cfe925a67d3ed683192283796c5a2.png 760w,
               /media/images/ICPR-first/new_comparison_hu515bf716bc1e00894b5ecf56365aca5d_4422147_1200x1200_fit_lanczos_3.png 1200w&#34;
               src=&#34;http://xiaoqiangzhou.cn/media/images/ICPR-first/new_comparison_hu515bf716bc1e00894b5ecf56365aca5d_4422147_227ec18cbae17f4c1e8f7312c7249f01.png&#34;
               width=&#34;760&#34;
               height=&#34;588&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Figure 2: Some qualitative results compared with state-of-the-arts on three datasets.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
  </channel>
</rss>
