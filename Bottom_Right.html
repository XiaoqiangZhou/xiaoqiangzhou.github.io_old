<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <font face="Times New Roman" />
    <title>Bottom Right</title>
</head>
<br />


<h1>About Me</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">I am a second-year Ph.D student in the
        <a href="http://en.ustc.edu.cn/" target="_blank">
            University of Science and Technology of China (USTC).
        </a> <br>
        I joined the USTC-NLPR Joint-PhD program, under the co-supervision of Prof. Tieniu Tan, Prof. Ran He and Prof.
        Zilei Wang.<br>
        Currently, I work at Center for Research on Intelligent Perception and Computing, Institute of Automation,
        Chinese Academy of Sciences
    </font>
</p>


<h1>Research Interest</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">Computer Vision, Deep Learning</font>
</p>

<h1>Education</h1>
<hr width=775px align="left" />
<img src="ustcblue.jpg" , width=100px height=100px style="float:left" />
<div style="float:left">
    <font size="4.5">
        <ul>
            University of Science and Technology of China (USTC)
            <li>Ph.D, Automation, USTC, 2019-Now</li>
            Advisors: Tieniu Tan, Ran He, Zilei Wang
            <li>B.E., Electronic Engineering and Information Science, USTC, 2015-2019</li>
            Academic Records: GPA: 3.72/4.30 (ranking top 15% in school)
        </ul>
    </font>

</div>
<br />
<br />
<br />
<br />
<br />
<br />


<h1>Academic Experience</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">
        <ul>
            <li>2020/05-2020/07</li>
            Research Assistant: Institute of Automation, Chinese Academy of Sciences<br>
            <font color="blue"><b>Paper: Free-Form Image Inpainting via Contrastive Attention Network (ICPR 2020
                    oral)</b></font><br>
            Authors: Xin Ma, <b>Xiaoqiang Zhou</b>, Huaibo Huang, Zhenhua Chai, Xiaolin Wei, Ran He.<br>
            <!--Abstract: We propose a self-supervised Siamese inference network to improve the networkâ€™s <br>
            robustness and generalization. Furthermore, we propose a multi-scale decoder with a novel <br>
            dual attention fusion module to fuse the restored and known regions in a smooth way.-->
            <li>2020/04-2020/09</li>
            Research Intern: Base Computer Vision Group, Meituan, Beijing, Mentor: Dr. Zhenhua Chai<br>
            <b>Project: Image Watermark Removal</b><br>
            We implement and deploy an image watermark removal algorithm for Meituan Dianping. The<br>
            service call is more than 300k times per day
            <li>2019/09-2020/03</li>
            Research Assistant: University of Science and Technology of China<br>
            <font color="blue"><b>Paper: Semantic Image Inpainting with Contrastive Relation Network (ICPR 2020
                    oral,<br>
                    Best Scientific Paper Award)</b></font><br>
            Authors: <b>Xiaoqiang Zhou</b>, Junjie Li, Zilei Wang, Ran He, Tieniu Tan.<br>
            <!--Abstract: We propose a novel graph-based relation network to model the relationship existed<br>
            in corrupted image. In relation network, both intra-relationship for pixels in the same semantic<br>
            region and inter-relationship between different semantic parts are considered.-->
            <li>2018/11-2019/03</li>
            Research Intern: Internet Media Group, MSRA, Beijing, Mentor: Dr. Chong Luo<br>
            <b>Demo: Video Synopsis, Microsoft TechFest 2019</b><br>
            We use existed detector and tracker to extract tracklets. Later, tracklets are rearranged to<br>
            reduce the video length, followed by image synthesis. This demo is selected into
            <li>2018/03-2018/04</li>
            Research Assistant: Multimedia Computing & Communication Lab, Advisor: Prof. Wengang Zhou<br>
            <b>Experiment: Compare performance of SIFT and R-MAC in visual localization task</b><br>
            <!--I record a database video and query videos in campus, while query videos are shorter and<br>
            captured in a different light or weather condition. Using SIFT and R-MAC descriptor as the<br>
            image feature separately, I compare their performance on this task.-->
        </ul>
    </font>
</p>


<h1>Computer Skills</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">
        <ul>
            <li>Languages: Python, C/C++, MATLAB, Markdown, LATEX</li>
            <li>Framework: PyTorch, Tensorflow</li>
            <li>Systems: Linux, Microsoft Windows</li>
        </ul>
    </font>
</p>


<h1>English Ability</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">
        <ul>
            <li>CET4: 588 CET6: 563</li>
            <li>TOEFL: 89 (R:27 L:22 S:19 W:21)</li>
        </ul>
    </font>
</p>

<h1>Scholarship</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">
        <ul>
            <li>2018 Excellent Student Scholarship</li>
            <li>2017 National Endeavor Scholarship</li>
            <li>2017 Sumsung Scholarship</li>
            <li>2016 National Endeavor Scholarship</li>
            <li>2016 Excellent Student Scholarship</li>
        </ul>
    </font>
</p>

<h1>Hobby</h1>
<hr width=775px align="left" />
<p>
    <font size="4.5">
        <ul>
            <li>Books</li>
                Read about 25 books every year
            <li>Movies</li>
                Have watched about 700 movies in total
            <li>Economics, Finance and Investments</li>
                Have got some qualification certificates, like securities, securities analyst, fund and futures.
            <!--<ul>
                <li>Securities Qualification Certificate</li>
                <li>Fund Qualification Certificate</li>
                <li>Futures Qualification Certificate</li>
            </ul>-->




        </ul>
    </font>
</p>


<body>
</body>

</html>